{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#url = 'https://stackoverflow.com/questions/58036793/how-to-identify-pixels-corresponding-to-a-particular-gps-coordinates-on-an-image'\n",
    "#url = 'https://stackoverflow.com/questions/55210213/jupyter-notebook-importerror-cannot-import-name-type'\n",
    "url = 'https://stackoverflow.com/questions/58863479/in-selenium-when-i-search-xpath-how-do-i-capture-the-element-two-positions-befo'\n",
    "page = requests.get(url)\n",
    "print(page.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Python 3 and selenium I have this script to automate the search of terms in a site with public informationfrom selenium import webdriver# Driver PathCHROME = '/usr/bin/google-chrome'CHROMEDRIVER = '/home/abraji/Documentos/Code/chromedriver_linux64/chromedriver'# Chosen browser optionschrome_options = webdriver.chrome.options.Options()chrome_options.add_argument('--window-size=1920,1080')chrome_options.binary_location = CHROME# Website accessedlink = 'https://pjd.tjgo.jus.br/BuscaProcessoPublica?PaginaAtual=2&Passo=7'# Search termnome = \"MARCONI FERREIRA PERILLO JUNIOR\"# Waiting timewait = 60 # Open browserbrowser = webdriver.Chrome(CHROMEDRIVER, options = chrome_options)# Implicit waitbrowser.implicitly_wait(wait)# Access the linkbrowser.get(link)# Search by termbrowser.find_element_by_xpath(\"//*[@id='NomeParte']\").send_keys(nome)browser.find_element_by_xpath(\"//*[@id='btnBuscarProcPublico']\").click()# Searches for the text of the last icon - the last page buttonelement = browser.find_element_by_xpath(\"//*[@id='divTabela']/div[2]/div[2]/div[4]/div[2]/ul/li[9]/a\").textelement'»'This site when searching for terms paginates results and always shows as the last pagination button the \"»\" button.The next to last button in the case will be \"›\"So I need to capture the button text always twice before the last one. Here is this case the number \"8\", to automate page change - I will know how many clicks on next page will be neededPlease, when I search Xpath how do I capture the element two positions before?\n"
     ]
    }
   ],
   "source": [
    "#get question data\n",
    "#get tags - get from api, other metrics.\n",
    "question = soup.find('div', class_='post-text')\n",
    "q_data = question.get_text()\n",
    "q_data_fin = ''\n",
    "data_points = q_data.split('\\n')\n",
    "for p in data_points:\n",
    "    q_data_fin+=p\n",
    "print(q_data_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thank you for the basic math. It worked out for me with little bit of tweaking.\n"
     ]
    }
   ],
   "source": [
    "### get the comments from questions/answers search by id\n",
    "comment_xml = soup.find('li',id='comment-102480991')\n",
    "a = comment_xml.find_all('span',class_='comment-copy')\n",
    "print(a[0].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's a repository that streamlines mass plotting a map image. Hope this helps.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### fetch answers by id\n",
    "aid = 'answer-'+str(58276417)\n",
    "answer_xml = soup.find('div',id=aid).find(\"div\",class_='answercell post-layout--right').find('div',class_='post-text')\n",
    "print(answer_xml.get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
